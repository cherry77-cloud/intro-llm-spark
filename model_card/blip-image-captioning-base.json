{
   "BlipForConditionalGeneration": {
       "vision_model": {
           "embeddings": {
               "patch_embedding": "Conv2d(3, 768, kernel_size=(16, 16), stride=(16, 16))"
           },
           "encoder": {
               "layers": [
                   "12 x BlipEncoderLayer",
                   {
                       "self_attn": {
                           "dropout": "Dropout(p=0.0, inplace=False)",
                           "qkv": "Linear(768, 2304, bias=True)",
                           "projection": "Linear(768, 768, bias=True)"
                       },
                       "layer_norm1": "LayerNorm(768, eps=1e-05, elementwise_affine=True)",
                       "mlp": {
                           "activation_fn": "GELUActivation()",
                           "fc1": "Linear(768, 3072, bias=True)",
                           "fc2": "Linear(3072, 768, bias=True)"
                       },
                       "layer_norm2": "LayerNorm(768, eps=1e-05, elementwise_affine=True)"
                   }
               ]
           },
           "post_layernorm": "LayerNorm(768, eps=1e-05, elementwise_affine=True)"
       },
       "text_decoder": {
           "bert": {
               "embeddings": {
                   "word_embeddings": "Embedding(30524, 768, padding_idx=0)",
                   "position_embeddings": "Embedding(512, 768)",
                   "LayerNorm": "LayerNorm(768, eps=1e-12, elementwise_affine=True)",
                   "dropout": "Dropout(p=0.0, inplace=False)"
               },
               "encoder": {
                   "layer": [
                       "12 x BlipTextLayer",
                       {
                           "attention": {
                               "self": {
                                   "query": "Linear(768, 768, bias=True)",
                                   "key": "Linear(768, 768, bias=True)",
                                   "value": "Linear(768, 768, bias=True)",
                                   "dropout": "Dropout(p=0.0, inplace=False)"
                               },
                               "output": {
                                   "dense": "Linear(768, 768, bias=True)",
                                   "LayerNorm": "LayerNorm(768, eps=1e-12, elementwise_affine=True)",
                                   "dropout": "Dropout(p=0.0, inplace=False)"
                               }
                           },
                           "crossattention": {
                               "self": {
                                   "query": "Linear(768, 768, bias=True)",
                                   "key": "Linear(768, 768, bias=True)",
                                   "value": "Linear(768, 768, bias=True)",
                                   "dropout": "Dropout(p=0.0, inplace=False)"
                               },
                               "output": {
                                   "dense": "Linear(768, 768, bias=True)",
                                   "LayerNorm": "LayerNorm(768, eps=1e-12, elementwise_affine=True)",
                                   "dropout": "Dropout(p=0.0, inplace=False)"
                               }
                           },
                           "intermediate": {
                               "dense": "Linear(768, 3072, bias=True)",
                               "intermediate_act_fn": "GELUActivation()"
                           },
                           "output": {
                               "dense": "Linear(3072, 768, bias=True)",
                               "LayerNorm": "LayerNorm(768, eps=1e-12, elementwise_affine=True)",
                               "dropout": "Dropout(p=0.0, inplace=False)"
                           }
                       }
                   ]
               }
           },
           "cls": {
               "predictions": {
                   "transform": {
                       "dense": "Linear(768, 768, bias=True)",
                       "transform_act_fn": "GELUActivation()",
                       "LayerNorm": "LayerNorm(768, eps=1e-12, elementwise_affine=True)"
                   },
                   "decoder": "Linear(768, 30524, bias=True)"
               }
           }
       }
   }
}
